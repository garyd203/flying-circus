variables:
  # Default version of Python used in build steps
  build_python_version: '3.6'
  # Name of the zipped dist files when stored as an artifact in Azure
  dist_artifact: Flying_Circus_Wheel
  # Manually set flag for whether to release this build to PyPI (if other
  # preconditions are also met).
  #
  # Note that this is evaluated by the Pipelines condition as a truthy string,
  # so False is set as the empty string, and almost anything else evaluates
  # as True.
  do_release: '' # False
  # Name of the requirements file for test execution. This should include
  # all dependencies needed to run tests.
  requirements_test: requirements.txt
  # Set of Python + OS combinations that we test against.
  # This is expressed as a dictionary in a JSON string, that gets expanded
  # by the pipeline when required.
  test_matrix: |
    {
      'Linux_Py36': {
        'vm_image': 'ubuntu-latest',
        'py_version': '3.6'
      },
      'Linux_Py37': {
        'vm_image': 'ubuntu-latest',
        'py_version': '3.7'
      },
      'Mac_Py36': {
        'vm_image': 'macOS-latest',
        'py_version': '3.6'
      },
      'Mac_Py37': {
        'vm_image': 'macOS-latest',
        'py_version': '3.7'
      },
      'Windows_Py36': {
        'vm_image': 'windows-latest',
        'py_version': '3.6'
      },
      'Windows_Py37': {
        'vm_image': 'windows-latest',
        'py_version': '3.7'
      }
    }
  # Inline Python command that can be used to validate an install of the library
  validation_script: 'import flyingcircus; s = flyingcircus.core.Stack(); print(s.export())'

# Perform a build every time code is pushed to the master branch
trigger:
  # Each time we push code to master we get a separate build
  batch: false
  branches:
    include:
      - master

# Perform a validation build every time a PR is created that will merge into
# the master branch
pr:
  # Changes to the branch will cancel existing builds against the PR branch
  autoCancel: true
  branches:
    include:
      - master

stages:
  - stage: Checks
    jobs:
      - job: CodeStyle
        timeoutInMinutes: 5
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: $(build_python_version)
            displayName: 'Use Python $(build_python_version)'

          - script: |
              python -m pip install --upgrade pip
              pip install black
              black --check src setup.py tests tools
            displayName: 'black'

      - job: Test
        timeoutInMinutes: 10
        pool:
          vmImage: 'ubuntu-latest'
        strategy:
          matrix:
            Python36:
              python.version: '3.6'
            Python37:
              python.version: '3.7'
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - script: |
              python -m pip install --upgrade pip
              pip install -r $(requirements_test)
              pip install pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              pytest tests
            displayName: 'pytest'

      - job: WillThisBeARelease
        dependsOn: Test
        condition: |
          and(
            succeeded(),
            variables['do_release'],
            eq(variables['Build.SourceBranch'], 'refs/heads/master')
          )
        timeoutInMinutes: 1
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - script: |
              echo This build will be released to PyPI
            displayName: 'Just a print statement'

  - stage: Build
    condition: |
      and(
        succeeded(),
        eq(variables['Build.SourceBranch'], 'refs/heads/master')
      )
    jobs:
      - job: BuildWheel
        timeoutInMinutes: 5
        pool:
          vmImage: 'ubuntu-latest'
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: $(build_python_version)
            displayName: 'Use Python $(build_python_version)'

          - script: |
              python -m pip install --upgrade pip
              pip install -U twine wheel
            displayName: 'Install dependencies'

          - script: |
              python setup.py sdist bdist_wheel
              twine check dist/*
            displayName: 'Build wheel'

          - task: PublishBuildArtifacts@1
            inputs:
              pathtoPublish: dist/
              artifactName: $(dist_artifact)
            displayName: 'Publish Artifacts in Azure'

      - job: Validate
        dependsOn: BuildWheel
        timeoutInMinutes: 5
        strategy:
          matrix:
            $[ variables.test_matrix ]
        pool:
          vmImage: '$(vm_image)'
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(py_version)'
            displayName: 'Use Python $(py_version)'

          - task: DownloadBuildArtifacts@0
            inputs:
              buildType: 'current'
              downloadType: 'single'
              artifactName: '$(dist_artifact)'
              itemPattern: '**'
              downloadPath: '$(Build.ArtifactStagingDirectory)'
            displayName: 'Download Artifact'

          - script: |
              echo This script is circumlocutious because it needs to be cross-platform

              python -m pip install --upgrade pip

              echo You cant list a directory or change into it directly, because of
              echo platform-specific directory separators.
              echo Also, note that the ArtifactStagingDirectory variable contains a
              echo drive letter, so it cant be used in a Windows bash script.
              echo Hence we change into the directory one level at a time
              cd $(Build.ArtifactStagingDirectory)
              cd $(dist_artifact)

              echo You cant just do `pip install *.whl` because on Windows this looks
              echo for a file literally called "*.whl".
              echo Also, you cant pipe the `ls` output into pip, because theres
              echo no way to use stdin as a requirements file.
              echo Hence we use 2 commands with an intermediate file
              ls *.whl > localreq.txt
              pip install -r localreq.txt

              echo Validate the installed library
              python -c "$(validation_script)"
            displayName: 'Validate Wheel'

  - stage: Release
    # There isn't a way to add a manual approval step to a pipeline (I think
    # you're supposed to use a separate Release Pipeline, but they aren't
    # available as IaC yet), so we fudge it by using a variable that can be
    # overridden with a manual build.
    condition: |
      and(
        succeeded(),
        variables['do_release'],
        eq(variables['Build.SourceBranch'], 'refs/heads/master')
      )
    jobs:
      - deployment: PyPiLive
        # TODO As of July 2019 you can't set a timeout on a deployment job,
        # notwithstanding what the documentation says
        #timeoutInMinutes: 5
        pool:
          vmImage: 'ubuntu-latest'
        environment: pypi-live
        strategy:
          runOnce:
            deploy:
              steps:
                - task: UsePythonVersion@0
                  inputs:
                    versionSpec: $(build_python_version)
                  displayName: 'Use Python $(build_python_version)'

                - script: |
                    python -m pip install --upgrade pip
                    pip install -U twine wheel
                  displayName: 'Install dependencies'

                - task: TwineAuthenticate@0
                  inputs:
                    # This magic string is the name of a "Service Connection"
                    # in the "Settings" section of our Azure DevOps project,
                    # of type "Python package upload"
                    externalFeeds: 'PyPI'
                  displayName: 'Authenticate For PyPI'

                - script: |
                    # Note that automatic downloads in a deployment job are
                    # put into the workspace under the artifact name (and not,
                    # say, the temporary artifacts directory).
                    twine upload -r PyPI --config-file $(PYPIRC_PATH) $(Pipeline.Workspace)/$(dist_artifact)/
                  displayName: 'Upload to PyPI'
